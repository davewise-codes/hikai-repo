# Hikai — Memo Ejecutivo (v2)

## Infraestructura Operativa para Productos Digitales

---

## Contexto de mercado y justificación de la oportunidad

La IA ha sobreacelerado la creación de productos digitales: hoy es posible construir y lanzar mucho más rápido. Esto tensiona al resto de funciones porque **sostener el producto (marketing, CS, ventas, coordinación) no se ha acelerado al mismo ritmo**. El resultado es una brecha estructural entre velocidad de producto y capacidad operativa.

Además, el presupuesto tecnológico está cambiando de categoría: **SaaS tradicional se estanca, infraestructura de IA crece 40–60% YoY**. Los CFOs buscan capacidad real, no más herramientas. El gasto se mueve de “software” a “infraestructura que ejecuta trabajo”.

**Oportunidad:** crear una infraestructura operativa que elimine el cuello de botella de sostener productos digitales, y capturar ese presupuesto emergente de IA.

---

## Hikai: tesis central e insights fundacionales

**Tesis central:** la mayoría de soluciones IA mueven el cuello de botella (del trabajo al prompting o a la coordinación). **Hikai no lo mueve: lo elimina.** El trabajo operativo sucede sin empuje humano, sin pérdida de contexto y con continuidad real.

**El problema real ya no es inteligencia, es disciplina operativa**
Hoy cualquier equipo tiene acceso a modelos potentes. Lo difícil no es “saber qué hacer”, sino **mantener un sistema que ejecute sin fricción**:

- Disciplina (ritmo sostenido sin empuje humano)
- Persistencia (memoria real, no chats aislados)
- Sistemática (procesos repetibles y auditables)
- Coordinación (handoffs claros entre tareas/agentes)

**Cómo resolvemos la oportunidad de mercado**

- Construimos un sistema que ejecuta funciones operativas completas con memoria persistente.
- Vendemos atribuciones claras (ej: SEO técnico, contenido, product marketing) con outputs medibles y frecuencia definida.
- La accountability permanece humana: el CMO/founder define estrategia y resultados; Hikai ejecuta el trabajo operativo y mantiene el ritmo.

**Por qué no basta una infraestructura genérica**
Este tipo de sistema exige **domain expertise**: entender producto digital, traducirlo a capacidades de negocio y definir qué outputs importan. Una infraestructura genérica obliga al cliente a diseñar procesos, disciplinar el uso y reinyectar contexto. **Hikai elimina ese trabajo** con una arquitectura ya opinionada para esta vertical.

**Diferenciador frente a agentes IA genéricos**

- Los LLMs están democratizados; lo difícil es **la continuidad, la memoria estructurada y la orquestación**.
- Hikai es sistema, no agente: red de agentes coordinados con estado, trazabilidad y memoria acumulativa.
- Resultado: trabajo autónomo y sostenido, no respuestas ad-hoc.

**Breves pinceladas técnicas (solo lo esencial)**

- Modelo de datos opinado para producto digital y funciones de negocio.
- Orquestación de agentes especializados con handoffs explícitos.
- Memoria persistente con histórico y trazabilidad.
- Outputs confiables y auditables, diseñados para operar como un equipo humano.
- Timeline automático como “agencia de contexto” que alimenta todo el sistema.

---

## El negocio

**Cómo contrata un cliente**
Un cliente llega cuando ya tiene producto en crecimiento y marketing/CS/ventas no escalan al ritmo del desarrollo. Buscan eficiencia en esa función. Su racional es claro: **delegar ejecución operativa sin perder control estratégico**. Espera obtener **reducción de costes** con continuidad real, menos coordinación y trazabilidad del trabajo.

Qué espera obtener en la práctica:

- Ritmo sostenido de ejecución sin empuje humano
- Outputs medibles y consistentes (assets, entregables, planes)
- Memoria estructurada del producto y su narrativa
- Alineamiento automático con releases y evolución técnica
- Accountability humana intacta (la estrategia sigue siendo suya)

**Diferenciadores en el modelo**

- No vendemos outcomes ni seats; vendemos **atribuciones ejecutadas con continuidad**.
- Pricing separado en **workforce fee** (atribuciones) e **infrastructure fee** (uso real de LLM/compute).
- Es un modelo de infraestructura operativa, no SaaS tradicional.

**Captura de AI budget**

- El gasto en IA crece mientras SaaS se estanca.
- Hikai se compra como infraestructura AI (misma línea presupuestaria que créditos LLM, Cursor, etc.).
- Comparación real del buyer: “¿lo construimos nosotros con Claude API?” vs “lo compramos”.

**Unit economics (alto nivel)**

- Margen objetivo ~80% sobre workforce fee.
- Infra pagada por el cliente, sin riesgo de quemar caja.
- Escalabilidad lineal por atribuciones activas.

---

## Roadmap (super high level)

**Ahora (0–6 meses)**

- Timeline automático gratuito como “agencia de contexto”.
- Validar arquitectura core y engagement semanal.
- Milestone: 100 signups con uso recurrente.

**Siguiente (6–18 meses)**

- Primeros clientes pagando por workforces.
- Validar WTP, calidad sostenida y unit economics.
- Milestone: 10–20 clientes activos renovando.

**Más adelante (18+ meses)**

- Expandir a organizaciones más grandes (hasta 30 pax).
- Más atribuciones, mayor autonomía, integraciones enterprise básicas.
- Milestone: 50–100 clientes activos.

---

## Cierre: Por qué ahora

Tres tendencias convergen:

1. Crear productos digitales es 10x más fácil.
2. Sostenerlos sigue siendo doloroso y no escala.
3. Los presupuestos están pivotando hacia infraestructura AI.

**El presupuesto está ahí. La necesidad también. El timing es ahora.**
